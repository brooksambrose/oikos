---
title: 'CTAWG Handout: STM Paper Discussion'
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
---
# Structural Topic Models for Open-Ended Survey Responses , *pp. 1064*
 (pdf.pp. 1, 0%)



>> Collection and especially analysis of open-ended survey responses are relatively rare in the discipline and when conducted are almost exclusively done through human coding. We present an alternative, semiautomated approach, the structural topic model (STM) (Roberts, Stewart, and Airoldi 2013; Roberts et al. 2013), that draws on recent developments in machine learning based analysis of textual data. A crucial contribution of the method is that it incorporates information about the document, such as the author’s gender, political affiliation, and treatment assignment (if an experimental study). This article focuses on how the STM is helpful for survey researchers and experimentalists. The STM makes analyzing open-ended responses easier, more revealing, and capable of being used to estimate treatment effects. We illustrate these innovations with analysis of text from surveys and experiments, *pp. 1064*
 (pdf.pp. 1, 0.5%)



@ Our thanks to the Caltech SURF program, IQSS’s Program on Text Analysis, and Dustin Tingley’s dean support for supporting Jetson’s initial participation during the summer of 2012. Brandon Stewart gratefully acknowledges funding from a National Science Foun- dation Graduate Research Fellowship. Alex Storer helped get computers to do their job. We thank the following for helpful com- ments and suggestions: Neal Beck, Justin Grimmer, Jennifer Jerit, Luke Keele, Gary King, Mik Laver, Rose McDermott, Helen Milner, Rich Nielsen, Brendan O’Connor, Mike Tomz, and participants in the Harvard Political Economy and Applied Statistics Workshops, UT Austin Government Department IR Seminar, Visions in Methodology 2013, and Stanford Methods Seminar. Replication files are available in the AJPS Data Archive on Dataverse (http://dvn.iq.harvard.edu/dvn/dv/ajps). The supplementary appendix is available at http://scholar.harvard.edu/les/dtingley/les/ajpsappendix.pdf, *pp. 1064*
 (pdf.pp. 1, 4.1%)



# Why Open-Ended Responses?, *pp. 1065*
 (pdf.pp. 2, 9.5%)



## Our Contributions, *pp. 1066*
 (pdf.pp. 3, 13.8%)



# Statistical Models of Text, *pp. 1066*
 (pdf.pp. 3, 15.3%)



## A Heuristic Understanding of Statistical Topic Models, *pp. 1066*
 (pdf.pp. 3, 16.7%)



## Structural Topic Model, *pp. 1067*
 (pdf.pp. 4, 21.1%)



## Estimating Quantities of Interest, *pp. 1067*
 (pdf.pp. 4, 24.8%)



>> In all topic models, the analyst estimates for each docu- ment the proportion of words attributable to each topic, providing a measure of topic prevalence., *pp. 1067*
 (pdf.pp. 4, 25.1%)



>> The model also calculates the words most likely to be generated by each, *pp. 1067*
 (pdf.pp. 4, 25.3%)



>> topic, which provides a measure of topical content., *pp. 1068*
 (pdf.pp. 5, 26.1%)



!!! The inference on the STM quantities of interest is best understood by reference to the familiar regression framework. For example, consider topical prevalence; if we observed the topics for each survey response, we could generate a regression where the topic is the outcome vari- able, and the treatment condition or other respondent controls (e.g., gender, income, party affiliation), along with any interactions, are the explanatory variables. This regression would give us insight into whether our treat- ment condition caused respondents to spend a larger portion of their written response discussing a particu- lar topic. In our framework for analysis, we conduct this same regression, while simultaneously estimating the top- ics. This framework builds on recent work in political sci- ence on single-membership models, specifically Quinn et al. (2010) and Grimmer (2010), which allow topical prevalence to vary over time and author, respectively, *pp. 1068*
 (pdf.pp. 5, 27.3%)



!! Our model extends this framework by allowing topical prevalence to vary with any user-specified covariate. We also extend the framework to topical content. Word use within a particular topic comes from a regression, in this case a multinomial logistic regression, where the treat- ment condition and other covariates can change the rate of use for individual words within a topic, *pp. 1068*
 (pdf.pp. 5, 28.5%)



! We can also use the model to summarize the se- mantic meaning of a topic. Generally, these summaries are the highest probability words within a topic; how- ever, this tends to prioritize words that have high fre- quency overall but may not be semantically interesting. Following the insights of Bischof and Airoldi (2012), who demonstrate the value of exclusivity in summary words for topics, we label topics using simplified frequency- exclusivity (FREX) scoring (Roberts, Stewart, and Airoldi 2013; Roberts et al. 2013). This summarizes words with the harmonic mean of the probability of appearance un- der a topic and the exclusivity to that topic. These words provide more semantically intuitive representations of topic, *pp. 1068*
 (pdf.pp. 5, 29.9%)



## Model Specification and Selection, *pp. 1068*
 (pdf.pp. 5, 31.1%)



### Choices in Model Specification, *pp. 1068*
 (pdf.pp. 5, 31.5%)



> FIGURE 1 Quantities of Interest from STM, *pp. 1069*
 (pdf.pp. 6, 33%)



>> 1. QOI: Topical Prevalence Covariate Effects, *pp. 1069*
 (pdf.pp. 6, 33%)



>> 2. QOI: Topical Content Covariate Effects, *pp. 1069*
 (pdf.pp. 6, 33.5%)



>> 3. QOI: Document-Topic Proportions, *pp. 1069*
 (pdf.pp. 6, 33.9%)



>> 4. QOI: Topic-Word Proportions, *pp. 1069*
 (pdf.pp. 6, 34.5%)



### Model Selection Methods, *pp. 1069*
 (pdf.pp. 6, 36.1%)



 It is tempting to compute an approximation to the marginal likelihood and calculate a model selection statistic, but we echo previous studies in emphasizing that this maximizes model fit and not substantive interpreta- tion (Chang et al. 2009). Instead, we advocate quantitative , *pp. 1069*
 (pdf.pp. 6, 36.3%)



>> Specifically, we argue that a semantically interpretable topic has two qualities: (1) it is cohesive in the sense that high-probability words for the topic tend to co-occur within documents, and (2) it is exclusive in the sense that the top words for that topic are unlikely to appear within top words of other topics, *pp. 1069*
 (pdf.pp. 6, 36.7%)



! Semantic cohesion has previously been studied by Mimno et al. (2011) who develop a criterion based on co-occurence of top topic words and show that it corresponds with human eval- uation by subject matter experts., *pp. 1070*
 (pdf.pp. 7, 37.3%)



>> If words with high probability under topic i have low probabilities under other topics, then we say that topic i is exclusive. A topic that is both cohesive and exclusive is more likely to be semantically usefu, *pp. 1070*
 (pdf.pp. 7, 38.3%)



 While this simple measure is computationally effi- cient and interpretable, it cannot replace human judg- ment. The insight of the investigator is paramount here, and we strongly suggest careful reading of example texts. In these cases, the STM can direct the reader to the most useful documents to evaluate by providing a list , *pp. 1070*
 (pdf.pp. 7, 39.5%)



# Validating the Model: Simulations Tests and Examples, *pp. 1070*
 (pdf.pp. 7, 41.7%)



>> 1. Does the model recover treatment effects cor- rectly (i.e., low false positives and low false neg- atives)? 2. How does analysis compare to first estimating topics with LDA and then relating the topics to covariates?, *pp. 1070*
 (pdf.pp. 7, 42%)



> FIGURE 2, *pp. 1071*
 (pdf.pp. 8, 43.9%)



### Comparison to LDA and Other Alternate Models, *pp. 1071*
 (pdf.pp. 8, 44.6%)



> FIGURE 3 STM versus LDA Recovery of Treatment Effects, *pp. 1072*
 (pdf.pp. 9, 48.5%)



### Additional Material, *pp. 1072*
 (pdf.pp. 9, 49.4%)



# Data Analysis, *pp. 1073*
 (pdf.pp. 10, 50.5%)



## Public Views of Immigration, *pp. 1073*
 (pdf.pp. 10, 51.1%)



### Topic Analysis, *pp. 1073*
 (pdf.pp. 10, 51.9%)



> FIGURE 4 Vocabulary Associated with Topics 1 and 2, *pp. 1073*
 (pdf.pp. 10, 53.6%)



> FIGURE 5 A Representative Response from Topic 1, *pp. 1073*
 (pdf.pp. 10, 54%)



> FIGURE 6 A Representative Response from Topic 2 , *pp. 1073*
 (pdf.pp. 10, 54.5%)



> FIGURE 7 Words and Treatment Effect Associated with Topic 1, *pp. 1074*
 (pdf.pp. 11, 55.2%)



> FIGURE 8 Party Identification, Treatment, and the Predicted Proportion in Topic 1, *pp. 1074*
 (pdf.pp. 11, 55.8%)



### Covariate Analysis, *pp. 1074*
 (pdf.pp. 11, 56.1%)



> FIGURE 9 Fearful Response with High Topic 1, *pp. 1074*
 (pdf.pp. 11, 57.1%)



> FIGURE 10 Fearful Response with Low Topic 1, *pp. 1075*
 (pdf.pp. 12, 58.9%)



### Aggregate Comparison with Human Coders, *pp. 1075*
 (pdf.pp. 12, 59.2%)



## Intuition versus Reflection in Public Goods Games, *pp. 1075*
 (pdf.pp. 12, 62.2%)



### Decision Explanations across Treatment Conditions, *pp. 1075*
 (pdf.pp. 12, 63.7%)



> FIGURE 11 Topics from Intuition vs. Reflection Priming and Intuition Treatment Effect, *pp. 1076*
 (pdf.pp. 13, 65.2%)



> FIGURE 12 Topics from Time Pressure Experiment and Time Pressure Treatment Effect, *pp. 1076*
 (pdf.pp. 13, 65.8%)



### RespondentsWhoTalkaboutTheir IntuitionCooperate More, *pp. 1076*
 (pdf.pp. 13, 67.7%)



> FIGURE 13 Intuition Topics and Contributions, *pp. 1077*
 (pdf.pp. 14, 68.3%)



> FIGURE 14 Time Pressure Versus Delay Topics and Contributions, *pp. 1077*
 (pdf.pp. 14, 68.5%)



> FIGURE 15 Intuitive Topic Allowing for Different Vocabularies, *pp. 1077*
 (pdf.pp. 14, 69.8%)



> FIGURE 16 Comparison of Women and Men’s Vocabulary After Intuition Treatment , *pp. 1077*
 (pdf.pp. 14, 70.4%)



### Using Covariates for the Vocabulary: Gender, *pp. 1077*
 (pdf.pp. 14, 71.6%)



> FIGURE 17 STM Topics from ANES Most Important Problem, *pp. 1078*
 (pdf.pp. 15, 72.1%)



# ANES, *pp. 1078*
 (pdf.pp. 15, 74.9%)



> TABLE 1 Comparison of STM to Hand Coding, *pp. 1079*
 (pdf.pp. 16, 75.7%)



> FIGURE 18 Comparison of Covariate Relationships, *pp. 1080*
 (pdf.pp. 17, 81.9%)



# Conclusion, *pp. 1080*
 (pdf.pp. 17, 85.6%)



### Model Selection, *pp. 1081*
 (pdf.pp. 18, 87.9%)



### Power Calculations, *pp. 1081*
 (pdf.pp. 18, 88.7%)



# References, *pp. 1081*
 (pdf.pp. 18, 90.6%)



