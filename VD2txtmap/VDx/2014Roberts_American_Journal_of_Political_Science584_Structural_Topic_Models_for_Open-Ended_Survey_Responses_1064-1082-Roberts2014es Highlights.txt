2014Roberts_American_Journal_of_Political_Science584_Structural_Topic_Models_for_Open-Ended_Survey_Responses_1064-1082-Roberts2014es Highlights

Page 1, 0%: 
Structural Topic Models for Open-Ended Survey 
Responses 
Note: #

Page 1, 0.5%: 
Collection and especially analysis of open-ended survey responses are relatively rare in the discipline and when conducted 
are almost exclusively done through human coding. We present an alternative, semiautomated approach, the structural 
topic model (STM) (Roberts, Stewart, and Airoldi 2013; Roberts et al. 2013), that draws on recent developments in machine 
learning based analysis of textual data. A crucial contribution of the method is that it incorporates information about the 
document, such as the author’s gender, political affiliation, and treatment assignment (if an experimental study). This 
article focuses on how the STM is helpful for survey researchers and experimentalists. The STM makes analyzing open-ended 
responses easier, more revealing, and capable of being used to estimate treatment effects. We illustrate these innovations 
with analysis of text from surveys and experiments
Note: %%

Page 1, 4.1%: 
Our thanks to the Caltech SURF program, IQSS’s Program on Text Analysis, and Dustin Tingley’s dean support for supporting Jetson’s 
initial participation during the summer of 2012. Brandon Stewart gratefully acknowledges funding from a National Science Foun- 
dation Graduate Research Fellowship. Alex Storer helped get computers to do their job. We thank the following for helpful com- 
ments and suggestions: Neal Beck, Justin Grimmer, Jennifer Jerit, Luke Keele, Gary King, Mik Laver, Rose McDermott, Helen Milner, 
Rich Nielsen, Brendan O’Connor, Mike Tomz, and participants in the Harvard Political Economy and Applied Statistics Workshops, 
UT Austin Government Department IR Seminar, Visions in Methodology 2013, and Stanford Methods Seminar. Replication files are 
available in the AJPS Data Archive on Dataverse (http://dvn.iq.harvard.edu/dvn/dv/ajps). The supplementary appendix is available at 
http://scholar.harvard.edu/les/dtingley/les/ajpsappendix.pdf
Note: @

Page 2, 9.5%: 
Why Open-Ended Responses?
Note: #

Page 3, 13.8%: 
Our Contributions
Note: ##

Page 3, 15.3%: 
Statistical Models of Text
Note: #

Page 3, 16.7%: 
A Heuristic Understanding of Statistical 
Topic Models
Note: ##

Page 4, 21.1%: 
Structural Topic Model
Note: ##

Page 4, 24.8%: 
Estimating Quantities of Interest
Note: ##

Page 4, 25.1%: 
In all topic models, the analyst estimates for each docu- 
ment the proportion of words attributable to each topic, 
providing a measure of topic prevalence.
Note: %%

Page 4, 25.3%: 
The model also 
calculates the words most likely to be generated by each
Note: %%

Page 5, 26.1%: 
topic, which provides a measure of topical content.
Note: %%

Page 5, 27.3%: 
The inference on the STM quantities of interest is 
best understood by reference to the familiar regression 
framework. For example, consider topical prevalence; if 
we observed the topics for each survey response, we could 
generate a regression where the topic is the outcome vari- 
able, and the treatment condition or other respondent 
controls (e.g., gender, income, party affiliation), along 
with any interactions, are the explanatory variables. This 
regression would give us insight into whether our treat- 
ment condition caused respondents to spend a larger 
portion of their written response discussing a particu- 
lar topic. In our framework for analysis, we conduct this 
same regression, while simultaneously estimating the top- 
ics. This framework builds on recent work in political sci- 
ence on single-membership models, specifically Quinn 
et al. (2010) and Grimmer (2010), which allow topical 
prevalence to vary over time and author, respectively
Note: !!!

Page 5, 28.5%: 
Our model extends this framework by allowing topical 
prevalence to vary with any user-specified covariate. We 
also extend the framework to topical content. Word use 
within a particular topic comes from a regression, in this 
case a multinomial logistic regression, where the treat- 
ment condition and other covariates can change the rate 
of use for individual words within a topic
Note: !!

Page 5, 29.9%: 
We can also use the model to summarize the se- 
mantic meaning of a topic. Generally, these summaries 
are the highest probability words within a topic; how- 
ever, this tends to prioritize words that have high fre- 
quency overall but may not be semantically interesting. 
Following the insights of Bischof and Airoldi (2012), who 
demonstrate the value of exclusivity in summary words 
for topics, we label topics using simplified frequency- 
exclusivity (FREX) scoring (Roberts, Stewart, and Airoldi 
2013; Roberts et al. 2013). This summarizes words with 
the harmonic mean of the probability of appearance un- 
der a topic and the exclusivity to that topic. These words 
provide more semantically intuitive representations of 
topic
Note: !

Page 5, 31.1%: 
Model Specification and Selection
Note: ##

Page 5, 31.5%: 
Choices in Model Specification
Note: ###

Page 6, 33%: 
FIGURE 1 Quantities of Interest from STM
Note: %

Page 6, 33%: 
1. QOI: Topical Prevalence Covariate Effects
Note: %%

Page 6, 33.5%: 
2. QOI: Topical Content Covariate Effects
Note: %%

Page 6, 33.9%: 
3. QOI: Document-Topic Proportions
Note: %%

Page 6, 34.5%: 
4. QOI: Topic-Word Proportions
Note: %%

Page 6, 36.1%: 
Model Selection Methods
Note: ###

Page 6, 36.3%: 
It is tempting to compute an approximation to 
the marginal likelihood and calculate a model selection 
statistic, but we echo previous studies in emphasizing that 
this maximizes model fit and not substantive interpreta- 
tion (Chang et al. 2009). Instead, we advocate quantitative 
evaluations of properties of the topic-word distribution

Page 6, 36.7%: 
Specifically, we argue that a semantically interpretable 
topic has two qualities: (1) it is cohesive in the sense that 
high-probability words for the topic tend to co-occur 
within documents, and (2) it is exclusive in the sense that 
the top words for that topic are unlikely to appear within 
top words of other topics
Note: %%

Page 7, 37.3%: 
Semantic cohesion 
has previously been studied by Mimno et al. (2011) who 
develop a criterion based on co-occurence of top topic 
words and show that it corresponds with human eval- 
uation by subject matter experts.
Note: !

Page 7, 38.3%: 
If words 
with high probability under topic i have low probabilities 
under other topics, then we say that topic i is exclusive. A 
topic that is both cohesive and exclusive is more likely to 
be semantically usefu
Note: %%

Page 7, 39.5%: 
While this simple measure is computationally effi- 
cient and interpretable, it cannot replace human judg- 
ment. The insight of the investigator is paramount here, 
and we strongly suggest careful reading of example texts. 
In these cases, the STM can direct the reader to the most 
useful documents to evaluate by providing a list 
Note: 

Page 7, 41.7%: 
Validating the Model: Simulations Tests and 
Examples
Note: #

Page 7, 42%: 
1. Does the model recover treatment effects cor- 
rectly (i.e., low false positives and low false neg- 
atives)? 
2. How does analysis compare to first estimating 
topics with LDA and then relating the topics to 
covariates?
Note: %%

Page 8, 43.9%: 
FIGURE 2
Note: %

Page 8, 44.6%: 
Comparison to LDA and Other Alternate Models
Note: ###

Page 9, 48.5%: 
FIGURE 3 STM versus LDA Recovery of Treatment Effects
Note: %

Page 9, 49.4%: 
Additional Material
Note: ###

Page 10, 50.5%: 
Data Analysis
Note: #

Page 10, 51.1%: 
Public Views of Immigration
Note: ##

Page 10, 51.9%: 
Topic Analysis
Note: ###

Page 10, 53.6%: 
FIGURE 4 Vocabulary Associated with 
Topics 1 and 2
Note: %

Page 10, 54%: 
FIGURE 5 A Representative Response from 
Topic 1
Note: %

Page 10, 54.5%: 
FIGURE 6 A Representative Response from 
Topic 2 
Note: %

Page 11, 55.2%: 
FIGURE 7 Words and Treatment Effect Associated with Topic 1
Note: %

Page 11, 55.8%: 
FIGURE 8 Party Identification, Treatment, 
and the Predicted Proportion in 
Topic 1
Note: %

Page 11, 56.1%: 
Covariate Analysis
Note: ###

Page 11, 57.1%: 
FIGURE 9 Fearful Response with High 
Topic 1
Note: %

Page 12, 58.9%: 
FIGURE 10 Fearful Response with Low 
Topic 1
Note: %

Page 12, 59.2%: 
Aggregate Comparison with Human Coders
Note: ###

Page 12, 62.2%: 
Intuition versus Reflection in Public Goods 
Games
Note: ##

Page 12, 63.7%: 
Decision Explanations across Treatment Conditions
Note: ###

Page 13, 65.2%: 
FIGURE 11 Topics from Intuition vs. Reflection Priming and Intuition Treatment 
Effect
Note: %

Page 13, 65.8%: 
FIGURE 12 Topics from Time Pressure Experiment and Time Pressure Treatment 
Effect
Note: %

Page 13, 67.7%: 
RespondentsWhoTalkaboutTheir IntuitionCooperate 
More
Note: ###

Page 14, 68.3%: 
FIGURE 13 Intuition Topics and 
Contributions
Note: %

Page 14, 68.5%: 
FIGURE 14 Time Pressure Versus Delay 
Topics and Contributions
Note: %

Page 14, 69.8%: 
FIGURE 15 Intuitive Topic Allowing for 
Different Vocabularies
Note: %

Page 14, 70.4%: 
FIGURE 16 Comparison of Women and Men’s 
Vocabulary After Intuition 
Treatment 
Note: %

Page 14, 71.6%: 
Using Covariates for the Vocabulary: Gender
Note: ###

Page 15, 72.1%: 
FIGURE 17 STM Topics from ANES Most Important Problem
Note: %

Page 15, 74.9%: 
ANES
Note: #

Page 16, 75.7%: 
TABLE 1 Comparison of STM to Hand Coding
Note: %

Page 17, 81.9%: 
FIGURE 18 Comparison of Covariate Relationships
Note: %

Page 17, 85.6%: 
Conclusion
Note: #

Page 18, 87.9%: 
Model Selection
Note: ###

Page 18, 88.7%: 
Power Calculations
Note: ###

Page 18, 90.6%: 
References
Note: #

