Tradition and Innovation in Scientists’ Research Strategies
Jacob G. Foster⇑a
Andrey Rzhetskyb
James A. Evansb
aUniversity of California-Los Angeles
bUniversity of Chicago
Jacob Foster, Department of Sociology, University of California-Los Angeles, 264 Haines Hall, 375 Portola Plaza, Los Angeles, CA 90095; James Evans, Department of Sociology, University of Chicago, 1126 East 59th Street, Chicago, IL 60637 E-mail: foster@soc.ucla.edu; jevans@uchicago.edu
 
Next Section
Abstract

What factors affect a scientist’s choice of research problem? Qualitative research in the history and sociology of science suggests that this choice is patterned by an “essential tension” between productive tradition and risky innovation. We examine this tension through Bourdieu’s field theory of science, and we explore it empirically by analyzing millions of biomedical abstracts from MEDLINE. We represent the evolving state of chemical knowledge with networks extracted from these abstracts. We then develop a typology of research strategies on these networks. Scientists can introduce novel chemicals and chemical relationships (innovation) or delve deeper into known ones (tradition). They can consolidate knowledge clusters or bridge them. The aggregate distribution of published strategies remains remarkably stable. High-risk innovation strategies are rare and reflect a growing focus on established knowledge. An innovative publication is more likely to achieve high impact than a conservative one, but the additional reward does not compensate for the risk of failing to publish. By studying prizewinners in biomedicine and chemistry, we show that occasional gambles for extraordinary impact are a compelling explanation for observed levels of risky innovation. Our analysis of the essential tension identifies institutional forces that sustain tradition and suggests policy interventions to foster innovation.
sociology of science tradition innovation networks generative models biomedicine citations awards field theory
Why do scientists pursue a particular research problem? These decisions are consequential, not just for scientists but for science itself. Indeed, problem choice becomes more important as knowledge grows in scale and complexity (Evans and Foster 2011; Foote 2007). In an expanding universe of possible research questions, a topic that attracts intense investigation is separated from neglected or abandoned topics by more than just the contours of nature. Scientists’ choices matter: in aggregate, patterned choices give scientific knowledge its shape and guide its future evolution.
Research choice is central to many classic investigations in the sociology of science (Busch, Lacy, and Sachs 1983; Diamond 1994; Gieryn 1978; Merton 1938; Zuckerman 1978). While it has received sustained attention in qualitative studies, it has been neglected in recent large-scale quantitative analyses (Ding, Murray, and Stuart 2006; Guimerà et al. 2005; Murray and Stern 2007; Shwed and Bearman 2010; Stuart and Ding 2006; Wuchty, Jones, and Uzzi 2007). In this article, we examine scientific choice quantitatively and at scale, using published claims in contemporary biomedicine to make inferences about underlying choices and dispositions.
As the qualitative and historical literature notes, many factors influence a scientist’s choice of research problem. Some factors are particular to each scientist, and range from past interests and training (Kevles 1978; Malmgren, Ottino, and Amaral 2010) to serendipitous yet consequential encounters (Merton and Barber 2011) with new collaborators, expertise, or information (Evans 2010a; Shi, Foster, and Evans 2015). Other factors are shared across groups of scientists. Local factors reflect institutional context (Abbott 1999) or disciplinary culture (Abbott 2001; Knorr-Cetina 1999; Shapin 1995). For example, scientists in a large department may be unconstrained because they lack a common paradigm; those in an emerging subfield may be unconstrained because they have few accumulated assumptions. At the meso-scale lie factors that influence everyone in a particular discipline or field (Bourdieu 1975), like long-standing investments in particular methods and theories. The characteristic trajectory of a scientific career also shapes research choice. Graduate students, assistant professors, and eminent scientists select problems in profoundly different professional contexts, venturing risks with varied stocks of accumulated scientific capital (Bourdieu 1975) and varied opportunities to reap the reward (Merton 1968). At the largest scale are factors affecting every contemporary scientist, like the valorization of original contributions.1
These many factors can be systematically assembled using Bourdieu’s (1975, 2004) field theory of science. In this view, scientists occupy more or less dominant positions in a specific scientific field, depending on the amount and types of scientifically recognized capital they have accumulated. Capital could be economic (e.g., grant money) or socially embedded (e.g., relationships with important scientists and patrons). It could be cultural, involving familiarity with the institutions, mores, and collective imagination of a field. Alternatively, scientists’ capital could be technical, residing in skills, expertise, and intuition. Scientists “take a position” by pursuing particular research problems selected from the space of all those possible (Bourdieu 1975, 2004). These concrete actions are guided by the interplay between scientists’ positions in the field and their habitus: acquired systems of tastes, dispositions, and expectations. At stake are recognition by fellow scientists, other currencies for which recognition can be traded, and an improved position in the field.
Although long neglected by sociologists of science, Bourdieu’s distinctive approach has recently experienced a renaissance (Albert and Kleinman 2011; Camic 2011, 2013; Kim 2009; Panofsky 2011). This re-appropriation largely rests on a move to relax the autonomy of a given scientific domain and explore both its interchange with other domains and its hierarchical embedding in other fields.2 For example, Bourdieu’s approach has illuminated the idiosyncratic history of behavioral genetics (Panofsky 2011) and early-twentieth-century economics (Camic 2011). We adopt Bourdieu for a different reason: his field theory provides an organizing framework for the wealth of data now available about the outcome and consequences of scientific choice.
Using contemporary biomedicine as an example, we analyze the large-scale pattern of research claims and provide a strategic, dispositional account of scientific choice, drawing on the rich, published record of successful research choices and rewards. We focus here on the tension created by conflicting professional demands, which map to distinct strategies for accumulating recognition and resources. To remain in the research game requires productivity. Scientists typically achieve this by incremental contributions to established research directions. This may yield enough recognition to maintain a (relatively low) position. Achieving high status, by contrast, requires original and transformative contributions, often obtained by pursuing risky new directions (Merton 1957).
These conflicting demands create a tension between two broad strategies: productive tradition and risky innovation (Kuhn [1959] 1977).3 When following a conservative strategy and adhering to a research tradition in their domain, scientists achieve publication with high probability: they remain visibly productive, but forgo opportunities for originality. When following a risk-taking strategy, scientists fail more frequently: they may appear unproductive for long periods, like the seven years Andrew Wiles spent proving Fermat’s Last Theorem or the decade Frederick Sanger invested in developing the “Sanger method” of DNA sequencing.4 If a risky project succeeds, however, it may have a profound impact, generating substantial new knowledge and winning broad acclaim (Kuhn 1962). This strategic tension is repeatedly articulated as a dichotomy: in the sociology of science, as reliable “succession” versus risky “subversion” (Bourdieu 1975) or “relevance” versus “originality” (Whitley 2000); in the philosophy of science, as “conformity” versus “dissent” or “discipline” versus “rebellion” (Polanyi 1969); and in the study of innovation, as “exploitation” versus “exploration” (March 1991).5 Recent theoretical work supports this broad picture by highlighting the distinctive contributions (Weisberg and Muldoon 2009) and rewards (Kleinberg and Oren 2011) associated with traditional versus innovative strategies.
In this article, we explore the essential tension at scale, studying 6.5 million abstracts in biomedicine. We extend and elaborate Kuhn’s account of the essential tension using Bourdieu’s (1975, 1990, 2004) field theory. We argue that tradition and innovation label distinct regions in the space of possible research claims or “position-takings.” Scientists anticipate a certain risk and reward profile from each region. Through their choice of research problem, scientists invest in a particular mixture of tradition and innovation.
Our empirical analysis follows six steps: (1) we show how networks can be used to map the evolving landscape of chemical knowledge in biomedicine; (2) we identify clusters of knowledge within that map and demonstrate their stability; (3) we define a simple structural typology of research strategies corresponding to tradition and innovation, and we show that the distribution of published strategies is remarkably stable; (4) we use a simple probabilistic model to measure the broad habits of perception, attention, and choice—the habitus—that constrain research activity and support stability; (5) we quantify the relationship between strategy, risks, and rewards (citations) using several regression models; and (6) we explore citation accumulation and awards as incentives that discipline scientists’ choices and help structure the field. This matrix of incentives maintains the essential tension and is manifest in both the stable distribution of published research choices and the underlying habitus shaping them.
This article makes distinct contributions to the sociology of science, the study of networks, and quantitative methodology. It provides the first large-scale test of a key hypothesis in the sociology of science (the essential tension), drawing on a dataset of unusual size and quality to connect the structure of scientific content to multiple forms of reward, including citations and awards. We also make new connections between important although sometimes unfashionable streams of theory (Bourdieu 1975; Kuhn [1959] 1977), and extend Bourdieu’s internal approach to the scientific field in new directions. Methodologically, we develop and deploy quantitative approaches for operationalizing key concepts in the sociology of science (e.g., position-taking, field, and habitus). Concretely, we demonstrate that contemporary network analytic methods (Rosvall and Bergstrom 2008) can be extended beyond citations to map the structure of content (scientific and otherwise) at a very large scale. We also show how concepts from information theory (Cover and Thomas 1991) and techniques of probabilistic modeling (Cokol et al. 2005) can be used to quantify rich qualitative concepts like novelty and the scientific habitus. Above all, our core question—how do I choose what to study?—is of reflexive interest to all scholars and scientists.6
Previous Section
Next Section
The Essential Tension and Scientific Habitus

Kuhn ([1959] 1977) introduced the notion of the essential tension at a conference motivated by Cold War concerns about declining originality, innovation, and scientific competitiveness in the United States (a persistent concern; see Cowen 2011). The conveners, all psychologists, had framed the conference around a dichotomy between convergent and divergent styles of thinking. Convergent thinking was conservative, oriented toward consensus and shared patterns of thought (Kuhn [1959] 1977). Divergent thinking, by contrast, was radical, characterized by “flexibility and open-mindedness” (Kuhn [1959] 1977:226). According to most of the conference speakers, divergent thought was essential for scientific progress, yet it was being stifled by the U.S. educational system.
Kuhn challenged the privileged role of divergent thinking in his remarks. In an argument prefiguring the better-known Structure of Scientific Revolutions (1962), Kuhn provided a functionalist account of the interplay between tradition (convergent thinking) and innovation (divergent thinking). Tradition focuses everyone on the same problems and methods and creates a well-defined community of practice. This particular constellation of problems and methods eventually exhausts itself, paving the way for revolution. In this way, convergent research within a tradition ushers in the next turn in an endless cycle of revolution and normal science (Kuhn [1959] 1977).7 Kuhn ([1959] 1977:234) observed that “work within a well-defined and deeply ingrained tradition seems more productive of tradition-shattering novelties than work in which no similarly convergent standards are involved.” This argument places Kuhn squarely within the functionalist paradigm of Merton’s sociology of science; consider Merton’s claim that original contributions are rewarded precisely because that is how knowledge grows (Guetzkow, Lamont, and Mallard 2004; Merton 1942).
For Kuhn ([1959] 1977:229), the primary mechanism that maintains tradition is education: the solution of textbook problems “that the profession has come to accept as paradigms.” Although Kuhn ([1959] 1977:227) acknowledged that tradition is “reinforced by subsequent life in the profession,” Kuhn’s scientists are above all trained to work within a tradition—to ignore most of the anomalies churned up by daily work. At the same time, they are acutely aware that long-term reputation depends on novel results that lead them beyond tradition (Merton 1957), hence the tension. In the Kuhnian account, tradition is externally imposed on the practicing scientist and followed obstinately until it finally breaks down. Innovation is a felix culpa, a fortuitous accident that befalls a scientist with just the right sensitivity to distinguish trivial from illuminating anomalies.
A more convincing version of the essential tension is presented in Bourdieu’s early writing on the sociology of science. Bourdieu (1975) frames science as a competitive field in which scientists face a strategic choice between “succession” and “subversion.” These categories map directly onto Kuhn’s tradition and innovation. Rather than offering a simple story of oversocialized scientists, in which tradition is inculcated and followed, Bourdieu emphasizes that tradition is continually re-created, and deviance punished, by the strategic choices of scientists regarding what to study and what to cite. Specific practices are patterned by the scientific habitus, which disposes researchers to perceive and act in ways “objectively adapted to their outcomes without presupposing a conscious aiming at ends” (Bourdieu 1990:53). This habitus is produced by each scientist’s education and her experiences doing science and seeing science done by others. The dispositions of the habitus, in turn, are oriented toward competition for peer recognition, the primary capital of science. Tradition is maintained insofar as the habitus disposes scientists to reproduce past research in their own studies and censor novelty in the work of others. Practices too far outside tradition are neglected, while continued investment in old questions enhances the scientific capital of those with stakes in them. At the same time, scientists able to stake new positions—to muscle research questions inside the bounds of legitimacy—can subvert tradition and receive outsized recognition. Not only are these scientists early investors in a new research enterprise; they have successfully exercised symbolic power in defining a new question, topic, or method as legitimate (Bourdieu 1991). A scientist’s recognition scales in proportion to the extent of her subversion and the scientific redefinition it entailed.
Although the use of tradition or innovation strategies in pursuit of recognition should reflect the specificity of habitus, position, capital, opportunity, and risk, Bourdieu often suggests a “direct correspondence between an agent’s field position—dominant vs. dominated—and that same agent’s basic intellectual stance—orthodox vs. heterodox,” that is, tradition versus innovation (Camic 2011:279). Yet Kuhn ([1959] 1977) persuasively argues that tradition and innovation exist in productive tension for all scientists. We agree, viewing the aspiration to innovate as constitutive of the scientific habitus, even if it is rarely manifested. Blending Kuhn and Bourdieu, we develop a strategic account of the essential tension. Tradition is not pursued purely because of training; it is a reliable strategy to accumulate recognition. Innovation is not a happy accident; it is a risky gamble.8 Like Bourdieu, we embrace the multiscale nature of innovation, ranging from modest methodological advances to “tradition-shattering novelties” (Kuhn [1959] 1977:234) We expect that tradition and innovation will coexist (in tension) within fields, within scientists—even within papers.
Here we propose three ways in which strategic dispositions of the scientific habitus are formed and adapted to the accumulation of scientific capital; we will analyze all three quantitatively. First, scientific publications are the visible consequences of successful research choices. Scientists sample from that distribution in their reading and learn the prevalence of particular research strategies. This sampling also yields an informal estimate of the risk that a particular strategy will fail, yielding no publishable result and no peer recognition. Second, citations provide evidence of others’ judgments about particular research choices (Baldi 1998; Latour 1987; Merton 1942, 1988). When scientists observe how others cite different research strategies, they form an impression of the rewards each provides. Subjective assessments of the variance in citations create another impression of risk, this time regarding the outcome of a strategy once published. Some papers are massively cited, some not at all. Finally, awards reveal the long-term consequences of particular research choices. Awards concretize the esteem that represents the highest reward in the field of science (Merton 1973). Hence, the behavior of award-winning scientists provides an aspirational model for the younger generation. In Bourdieu’s (1986) framework, modest citations and major awards represent two institutionalized pathways to scientific capital, through which scientists learn the returns to tradition and innovation.
Stepping back from this theoretical account, let us paint a practical picture linking individual action to field structure: A scientist must decide what to work on next. Her position in the field is defined by her particular history, standing, relationships, and equipment (e.g., familiar chemicals, diseases, methods, and instruments). Based on this position, a number of possible research questions present themselves. These possible questions are colored by existing categories: practical or impractical, fundable or not fundable, patentable or not patentable (Evans 2010b; Fleming and Sorenson 2004; Washburn 2005), and traditional or innovative. Most questions, however, will not come to mind, and some, like those deemed not fundable or too innovative,9 may be ignored. Her categorizations and subsequent research choices are informed by expectations of outcome: How many other scientists pursue similar questions? How often do they fail? How often are innovative findings rejected (how often has she herself rejected them in the article review process)? If published, what is the reaction? Do they attract citations? Are they canonized with awards?
Research on the sociology, economics, and management of innovation independently grounds several aspects of this story. A wave of recent papers suggests that commercial opportunities (Evans 2010b), pressures (Vallas and Kleinman 2007), and commercially related policies (Berman 2012) can change the composition of scientific research and the choices that guide it.10 Other work examines the influence of high position (e.g., conferred by awards) on the reception of a scientist’s work (Azoulay, Stuart, and Wang 2013). Scholars have also explored the relationship between risk and reward. In the context of patents, Fleming (2001) demonstrates how risky combinations of patentable components are associated with higher variance and lower average citations. Uzzi and colleagues (2013) recently showed how a few atypical combinations of cited journals are associated with higher scientific impact, but only when contextualized with many typical journal pairings.
Management scholars Bateman and Hess (2015: Supporting Information p. 1) found that diabetes researchers judged a hypothetical “focused and specialized project” (i.e., tradition) less risky than a “broad project that spans several topical domains” (i.e., innovation). Surveyed researchers were less likely to pursue the risky project, viewing the specialized one as “potentially very important” and a more “significant opportunity.” In short, diabetes researchers perceived innovation as risky and preferred to follow the more conservative course, as our theory suggests.
Finally, research has elucidated the role of awards in stimulating scientists to take risks (Wright 1983). Azoulay, Graff Zivin, and Manso (2011) recently found that prestigious, long-term Howard Hughes Medical Institute grants, which support investigators for at least five years, are associated with the propensity to publish more highly cited articles than investigators sustained by short-term NIH grants. Our article builds on this work by (1) integrating these insights and findings within the context of a substantial empirical case; and (2) linking them to the content of research papers, the topic of research choice, and a comprehensive theoretical framework.
The evidence and theory outlined here suggest that most published findings in well-developed fields should be expected and unsurprising.11 Such findings fit with tradition: scientists with the appropriate habitus are disposed to generate and acknowledge them as valid science. By contrast, unexpected findings should rarely reach publication. Tradition will be reliably but modestly rewarded with citations, whereas subversive innovation, if published, should display a higher average and variance in acclaim.12 Finally, unexpected findings should be over-represented in the work of high-achieving scientists. Scientific capital is disproportionately awarded for work that alters the scope of accepted knowledge.
In this article, we examine these claims quantitatively, in the context of biomedicine. We focus on knowledge about chemical relationships in biomedicine; as a shorthand, we refer to this as “biomedical chemistry.” This focus on chemical relationships might seem overly narrow. To the contrary, our chemical entities range from small molecules (like most pharmaceuticals) to large macromolecules (like DNA and proteins). Knowledge about these chemical relationships stretches from organic chemistry to biochemistry to molecular biology, and proxies for everything from assays to treatments to diseases. Biomedical papers bring together methods and diseases in addition to chemicals, but the reductive paradigm of contemporary biomedicine makes chemicals an especially effective trace of its knowledge. A method often involves a chemical intervention; a disease usually has a chemical signature.
Knowledge Networks and Network Strategies
The document is the fundamental unit of analysis in most large-scale quantitative studies of scientific behavior (Cronin and Atkins 2000; Menczer 2004). Scholars use citations between documents to identify innovations (Chen et al. 2009; Funk and Owen-Smith 2012) and outline the structure of scientific fields (Rosvall and Bergstrom 2010). In our content-centered approach, basic conceptual entities and their relationships are the fundamental units of analysis. These entities and relationships weave a network of research possibilities, corresponding to “the space of search paths” or “network of possible wanderings” involved in human problem-solving (Newell and Simon 1972:82). In this picture, scientists both navigate the network of knowledge and build it through their research efforts. In the knowledge network of biomedical chemistry, the basic entities are molecules. The “relationships” between them can be reactions, interactions, or associations. These relationships inscribe the combinatorial “space of possible position-takings” or research questions. In pursuing a project, scientists take a stand on the existence of those relationships. When a paper is published, that stance becomes public and (minimally) legitimate. If the relationships in question are already established, tradition is reproduced, little reputation is staked, and little is gained. If published relationships are new, scientists are asserting scientific power and they accumulate reputation and scientific capital to the extent that others recognize the importance of those new relationships (Bourdieu 1990).
We propose the following coarse taxonomy of research strategies, corresponding to structurally distinct contributions to the network of scientific knowledge (Newman 2003). Our taxonomy builds on extensive work in science studies and research on innovation that uses the position of article and patent elements (e.g., citations, patent classes, and coarse topics) within a broader techno-scientific network as indicators of novelty and importance (Fleming, Mingo, and Chen 2007; Hargadon and Sutton 1997; Latour 1987; Leahey, Beckman, and Stanko 2013; Leahey and Moody 2014; Uzzi et al. 2013). A researcher may propose a relationship involving completely unexplored entities, making a jump beyond current knowledge (Cokol et al. 2005).13 She may also test a relationship between previously explored entities, either asserting a new (not previously published) relationship or repeating a relationship proposed before. New and repeat relations, in turn, can be either consolidations or bridges. This distinction rests on the observation that recognized relationships are not distributed evenly across the knowledge network. Socially organized scientific attention creates dense clusters of related chemicals, mirroring scientific subfields. See the Data, Methods, and Results section for an explanation of how we identify these clusters, and Table 1 for details about the most prominent ones. Joining entities within the same cluster provides further consolidation of the cluster, deepening knowledge in that domain and tightening established categories. Linking entities from distinct knowledge clusters creates a bridge between them, altering the connectivity of the knowledge network and weaving loosely connected regions more tightly together. Figure 1 illustrates the five strategies available to a scientist facing a network of known scientific relationships: jump, new consolidation, new bridge, repeat consolidation, or repeat bridge. Note that jump, new consolidation, and new bridge correspond to varying degrees of innovation (adding new relationships). Repeat consolidation and repeat bridge correspond to tradition (reproducing established relationships). This taxonomy is especially well-suited to fields like biomedicine where well-defined entities participate in a “molecular” logic of combination. Here, innovation corresponds transparently to new combinations. Other fields may involve other logics, such as fractal differentiation in sociology (Abbott 2001) or subsumption of the particular to the general in mathematics (for other examples, see Lamont 2009). In such fields, tradition and innovation may require a different operationalization from that adopted here.
View this table:
In this window In a new window
Download to PowerPoint Slide
Table 1.
Largest Chemical Clusters Induced by Map Equation from the MEDLINE Chemical Term Network
Figure 1.
View larger version:
In this page In a new window
Download to PowerPoint Slide
Figure 1.
Scientific Strategies in a Network
Note: Nodes represent chemicals and links represent chemical relationships. The bottom panel shows our proposed taxonomy in schematic form. Labels apply to dashed links.
Previous Section
Next Section
Data, Methods, and Results

Our analysis follows six distinct steps and connects to the vignette of our practicing scientist, described earlier. In brief, our broad goals are as follows: map the space of chemical knowledge (Steps 1 and 2); identify the prevalence and stability of the various strategies (Step 3); construct a simple behavioral model of scientific attention that relates strategy prevalence with opportunity (Step 4); measure risks and rewards associated with various strategies using citations (Step 5); and explore two potential motivational mechanisms for scientists’ choices—maximizing citations and seeking outsized recognition (Step 6).
Note that our data reveal only the outcome of successful choices, that is, published papers. We have no way of accessing specific choices (which may fail) or specific dispositions (a problem shared by other field-theoretic analyses). As a result, our paper strictly documents the pattern of successful choices and their association with various rewards. From this we make inferences about underlying dispositions and choices.14
Step 1: Chemistry Data and Network Construction
Our network is built from 6,455,756 abstracts in the NIH National Library of Medicine’s (NLM) MEDLINE collection, published from 1934 to 2008 and annotated by NLM with two or more chemical entities (see Part A of the online supplement [http://asr.sagepub.com/supplemental]). Chemical annotations were introduced in 1980 and applied to all articles indexed subsequently.15 We focus analysis on 1983 to 2008 to limit the effect of the introduction of chemical annotations on our results. We construct an evolving network (Newman 2003; Rosvall and Bergstrom 2010) from these annotated articles. For each year t, we examine all abstracts published in that year for chemical annotations. Each distinct chemical is a node in the network. Every time two chemicals appear in the same abstract in year t, we add a link between the corresponding nodes in the network for year t + 1 (Callon, Law, and Rip 1986). Note that articles are often annotated with more than two chemicals, and therefore contribute more than one chemical relationship. For example, an abstract annotated with five chemicals would correspond to an additional 10 links in the network. All relationships appearing in a given year enter the network together, as if published simultaneously. Coarse-graining the temporal evolution of the network in year-long chunks is an approximation, but necessary given uneven article date information and the computational demands of community detection.16 Individual links between chemicals, as documented in a particular publication, persist in the network, although we relaxed this assumption in sensitivity analyses. If the same pair of chemicals appears together in multiple publications, each appearance is added to the network as a distinct, persistent link. This construction yields a time-ordered sequence of weighted networks over chemicals. Given the network of accumulated knowledge for year t – 1, we classify the links associated with each publication in year t as one of the five strategies. This classification allows us to count the total number of times we observe each strategy in a given year.
Our procedure maps the rapidly growing network of chemical knowledge—published tradition—atop the space of possible chemical relationships. The number of chemicals has grown steadily since annotations were introduced in 1980 (see Figure 3). By 2008, the network has 181,078 nodes and 10,493,379 distinct links—84,709,977 links including repeats. Like many complex networks, the network of chemical knowledge is characterized by heavy-tailed distributions of degrees (number of chemicals to which a given chemical is connected) and link weights (number of co-appearances of two chemicals) (Barabási and Albert 1999; Cokol, Rodriguez-Esteban, and Rzhetsky 2007; Onnela et al. 2007); see Figure S1 in the online supplement.
This first step provides us with a detailed map of tradition for any given year in contemporary biomedical chemistry (1983 to 2008). To establish the space of possible research questions facing a scientist in a given year, we need to define knowledge clusters within that map.
Step 2: Community Detection and Knowledge Clusters
The social organization of scientific attention means that published chemical relationships bunch into clusters of chemicals that are frequently investigated together. These knowledge clusters reflect foci of scientific attention. We identify knowledge clusters using a popular community detection algorithm called the map equation (Rosvall, Axelsson, and Bergstrom 2009; Rosvall and Bergstrom 2008). It is one of the few algorithms capable of analyzing a network of our size, and it performs well in benchmark tests (Lancichinetti and Fortunato 2009). Knowledge clusters reflect the structure of chemical knowledge as expressed in journal articles: chemicals that appear together frequently in articles will be clustered together. We confirmed the robustness of cluster-dependent results against alternative subfield definitions induced by journal classifications and MEDLINE’s MeSH ontology (see Part B and Table S1 in the online supplement).
Community detection algorithm
Community detection algorithms reveal intermediate structures in large, complex networks (Bruggeman, Traag, and Uitermark 2012; Shwed and Bearman 2010). What structure is relevant to our scientists? Imagine these scientists as they explore the network of chemical knowledge, wandering mentally from one chemical to another across previously published connections. An individual scientist’s impression of the structure of chemical knowledge (tradition) in any given year can be coarsely approximated by the trajectory of a random walk on the knowledge network (see Austerweil, Abbott, and Griffiths 2012). Knowledge clusters are regions where the wandering process tends to get stuck before moving on.
The map equation provides a community detection scheme that precisely mirrors this picture (Rosvall et al. 2009; Rosvall and Bergstrom 2008). Formally, the algorithm minimizes the description length of a random walk on the network given a two-level labeling (higher-level labels for communities and lower-level labels for nodes within communities). Heuristically, the algorithm finds partitions such that the random walker spends a long time within a given community, on average, before transitioning to a new community. It thereby picks out subsets of nodes with dense intra-connection. This heuristic corresponds to the dynamic perception of subfields by scientists: as they explore the chemical knowledge network, they group together chemicals that frequently appear in the same papers via associative learning (Hebb 1949).
Knowledge clusters
To extract the knowledge clusters used to categorize links added at time t, we consider the entire network uncovered in all years prior to t. This choice for modeling temporality captures the gradual accumulation of chemical knowledge and is naturally conservative. While it intrinsically biases cluster detection toward stability, we view this as both desirable and realistic. Under this approach, knowledge clusters, which proxy for scientists’ shared perception about the natural divisions of chemical knowledge, change substantively only in response to sustained changes in patterns of attention and published relationships. In the intervening period, the articles that drive change are likely to be perceived as altering the organization of chemical knowledge—and they are classified in exactly this way by our approach.17
Our community detection procedure discovers scientifically plausible knowledge clusters in this network. Given the network up to time t, we define knowledge clusters for time t by selecting the best partition (i.e., the one that minimizes the description length) out of 50 randomly seeded iterations of the map equation community detection algorithm. Multiple iterations are performed to avoid a local minimum in the solution space (Rosvall et al. 2009). We selected 50 as a practical number of iterations; more iterations would have been prohibitive computationally. The coherence of the clusters over time (Figure 2) and the face validity of clusters (Table 1) give us confidence that we are not in a local minimum of the partition-space.
Figure 2.
View larger version:
In this page In a new window
Download to PowerPoint Slide
Figure 2.
Largest MEDLINE Knowledge Clusters, 1983 to 2003
Source: Using the map equation algorithm and associated alluvial and network diagram software (Rosvall and Bergstrom 2008, 2010).
Note: Here we show an alluvial diagram for the chemical network at four time points: 1983, 1990, 1996, and 2003. Only the top 15 knowledge clusters are shown. Different shades of gray are assigned based on cluster membership in 2003 and follow chemicals back to the earlier networks. Clusters are quite stable. The major events visible are the emergence of a knowledge cluster associated with DNA and RNA (DNA and Molecular Biology) from Core Biological Chemistry and the growing importance of Second Messenger System. These shifts occur against a background of continuity. For example, the clusters Neurotransmitters and Hormones (Reproductive, Adrenal, Pituitary) persist with little change across 20 years. The network diagrams below each year emphasize the structural stability of the network; the links shown correspond to the highest flow between subfields.
On the whole, knowledge clusters are quite stable. To demonstrate this, we use a visualization technique developed by Rosvall and Bergstrom, the “alluvial diagram” (Bruggeman et al. 2012; Rosvall and Bergstrom 2010). This technique tracks nodes from their assigned knowledge clusters at time t to their locations at time Formula and represents the movement via a ribbon. Figure 2 shows a sequence of visualizations covering the 15 largest clusters for the period 1983 to 2003. These represent the vast majority of flow in the network. Different shades of gray are assigned based on cluster membership in 2003 and follow chemicals back to earlier networks. Most of the alluvial diagram consists of thick ribbons, illustrating the stability of these knowledge clusters. We further quantify stability as follows. For clusters that persist from time t to time Formula , we find the cluster in Formula with the largest overlap and calculate the percent of chemicals in the cluster at time t that are clustered together in time Formula . In Table 1, we list these percentages for the clusters shown in Figure 2.18 We also compute the average percentage over all clusters, weighted by the number of chemicals in the cluster. For clusters in 1983 and 1990, the average overlap is 73 % for 1990 and 1996, it is 76 % and for 1996 and 2003, it is 78 percent. These results demonstrate the stability of these knowledge clusters over long periods.
Knowledge clusters change over time as shifts in scientific attention and publication add new chemicals, move chemicals to another cluster, merge clusters together, or split them apart. Because we allow chemical knowledge to accumulate, large changes in the cluster structure reflect sustained changes in publication patterns. The major events visible in Figure 2 are meaningful: for example, the emergence of a knowledge cluster associated with DNA and RNA (DNA and Molecular Biology) from the large cluster labeled Core Biological Chemistry. Such shifts, however, occur against a background of continuity. For example, the clusters Neurotransmitters and Hormones (Reproductive, Adrenal, Pituitary), persist with little change across the decades, while Second Messenger System grows in importance, corresponding to a well-established increase in research on intercellular communication.19 The network diagrams beneath each year emphasize the structural stability of the network, with links corresponding to the highest flows between subfields.
Table 1 lists the top 10 chemicals (by PageRank) for each knowledge cluster in the 2003 network (shown in Figure 2). The coherence of these lists demonstrates the scientific plausibility of the knowledge clusters.20 Similarly, the relationships and strategies identified by our network analysis are scientifically meaningful. For example, a 2007 article (Zemlyak et al. 2007) includes a new consolidation within a neurobiology-related knowledge cluster. This paper shows that neuronal tubulin-preferring agent NAPVSIPQ, a neuroprotective oligopeptide, defends neurons against neurotoxic kainic acid. Not only is the link between NAPVSIPQ and kainic acid a new and meaningful one, it also makes sense for both chemicals to be located in the same neurochemical cluster, and for their connection to be typed as a new consolidation of that cluster.21
Now that we have extracted the knowledge clusters for each year, we can fully define the space of possible research questions and sort them into our taxonomy of research strategies. In the third step, we explore the prevalence of each strategy by establishing how many published papers pursue questions in each category.
Step 3: Prevalence and Stability of Strategies
Strategy definitions
Our taxonomy of strategies, defined briefly earlier, is specified as follows:22 jumps involve at least one chemical that joined the network in the current year t; new consolidations connect known chemicals from the same knowledge cluster with no link between them in year t – 1; new bridges connect known chemicals from different knowledge clusters with no link between them in year t – 1; repeat consolidations reconnect chemicals from the same cluster that already have a link between them in year t – 1; and repeat bridges reconnect chemicals from different clusters that already have a link between them in year t – 1. Using these strategy definitions, we assign a strategy type to every link that joins the network in year t and count the instances of each strategy.
Strategy frequency
Pooling counts across all years, we find that the frequency of each strategy in the published literature from 1983 to 2008 is inversely related to its plausible risk of failure, as expected for a mature science. Repeat strategies, which correspond to tradition, were six times more frequent than new or jump strategies, which correspond to innovation (85.8 versus 14.2 percent). New bridges and new consolidations were more common than jumps by roughly the same proportion, tracking more and less extreme forms of innovation (12.4 versus 1.8 percent). Strategies that build incrementally on past knowledge appear more frequently not only because they are pursued more frequently, but also because non-incremental strategies are prone to fail. Whether a research project does not work or the resulting publication is censored by peer review, the results remain unpublished and invisible to science.
Yearly strategy distributions
We refer to the relative frequency of strategies within a year as the strategy distribution (see Figure 3A, solid lines). To assign confidence intervals to the relative frequencies, we model them as draws from a multinomial distribution with five types. We use the confidence interval proposed in Quesenberry and Hurst (1964) with the tighter bound introduced by Goodman (1965). The resulting distribution of scientific strategies remained remarkably stable over the period studied. The black arrow indicates the introduction of chemical annotations in 1980. From 1983 to 2008, the fraction of annual links corresponding to innovation strategies changed little, with jumps most rare, followed by consolidations, then bridges.
Figure 3.
View larger version:
In this page In a new window
Download to PowerPoint Slide
Figure 3.
Stable Strategies and Dynamical Attention
Note: (A) The empirical frequency of each strategy (solid line) with 95 percent confidence intervals smaller than the solid lines. Dotted lines show the predictions of our generative model. In 1980 (black arrow) chemical annotation is introduced in MEDLINE (see Part A of the online supplement). This distorts parameter estimates until 1987 (parameters for year t inferred from the six previous years). (B, left axis) The ratio Formula indicates an increasing concentration on established knowledge relative to new possibilities. (B, right axis) The preference for new consolidations over new bridges Formula grows and stabilizes. This preference does not carry over to repeat work Formula . 95 percent Bayesian credible intervals, shown in lighter shades of gray, are very small.
The observed prevalence of each research strategy reveals aspects distinctive to the development of biomedical chemistry. The discovery of new, important chemicals (jumping) is particularly uncommon and risky, but it represents the only mechanism by which the chemical universe can grow. The rarity of new consolidations may result from dense “presumed” knowledge within a subfield, especially negative knowledge. For example, many possible combinations are viewed as fruitless because they were previously attempted without success (Swanson 1990). The number of legitimate, unpublished consolidating links is relatively small, but these will tend to be surprising and consequential for the field. The higher frequency of new bridges, by contrast, is driven by combinatorial possibilities. As clusters multiply and shrink in size relative to the whole network, more opportunities arise to make links between versus within knowledge clusters.
Linear regressions of frequency on year show no significant temporal trend for new bridges, and significant but slight trends for jumps and new consolidations; their shifts each alter the mix of strategies less than 1 percent over the study period (see Part C and Table S2 in the online supplement). Prais-Winsten estimation, which takes autocorrelation into account, eliminated the detection of significant trends in jumps, new consolidations, and new bridges (p > .05), confirming the stability of the distribution of these strategies. We find mild, statistically significant trends in the repeat strategies, with repeat bridges passing repeat consolidations in 1990 and remaining stable thereafter.
This stability in the strategy distribution is surprising given the enormous changes in biomedical chemistry over the past few decades. The number of distinct chemicals that appear in MEDLINE annotations increased by more than an order of magnitude between 1980 and 2008 (see Figure 3). Because of this, there are many more new links to explore than known links (a factor of 22 more in 1983, growing to a factor of 188 by 2008). Because knowledge clusters are small relative to the entire system (the largest shrinks from 27.5 percent of the network in 1983 to 12.8 percent in 2008), the number of possible bridging links grows much faster than the number of possible consolidating links. The stability of strategic choices suggests that scientists are not responding to the changing space of research possibility. This excludes a simple Mertonian account of research choice, in which originality is the prime requisite of reward, and choice is determined largely by the opportunities that nature provides. Even if an overwhelming fraction of potential new links can be discarded as physically impossible or otherwise unworthy of exploration, biomedical scientists are not taking full advantage of opportunities to explore new relationships between chemicals.
To explore this further, in the next section we develop a simple generative behavioral model that relates the opportunities to pursue each strategy to the observed distribution of strategies. This model provides a coarse estimate of scientists’ preference for tradition over innovation, a core disposition of the biomedical habitus.
Step 4: Connecting Stability to Attention; A Generative Model of the Biomedical Habitus
The stability of the strategy distribution, despite dramatic expansions in research opportunity, implies that scientific attention is narrowing in focus. Indeed, both Kuhnian and Bourdieusian theories of the essential tension suggest potential narrowing mechanisms: for Kuhn, the paradigms provided by research training; for Bourdieu, stabilization of a field-specific (in this case, biomedical) habitus. Under both mechanisms, some opportunities will be discounted relative to others. A simple behavioral model of strategy selection allows us to measure this narrowing of scientific attention, connecting individual choices to aggregate stability. Our model takes the distribution of strategic opportunities into account and thus allows us to infer strategic preferences embodied in the biomedical habitus.
We assume that scientists choose probabilistically from the five possible strategies: jump, new consolidation, new bridge, repeat consolidation, and repeat bridge. For the purposes of this model, we treat each instance of strategy choice as an independent draw.23 If Formula is the probability of choosing a jump strategy, then
Formula
as the five strategies partition the sample space. It is plausible (and consistent with our motivating theory) that the distinction between jump, new, and repeat is most salient to choosing scientists. This distinction maps directly onto extreme innovation, innovation, or tradition, the categories most relevant to risk (and, as we show in Steps 5 and 6, to reward). We therefore model choice as a two-step process, in which researchers first choose between jump, new, or repeat and then choose to consolidate or bridge24 between subfields. Under these assumptions, the probabilities factorize:
Formula
Once a scientist chooses new or repeat, she must either consolidate or bridge conditional on that choice:
Formula
Substituting this into the previous equation, we have the following:
Formula
In other words, extreme innovation, innovation, and tradition provide a coarse partition of the sample space. The partition into jump, new consolidation, new bridge, repeat consolidation, and repeat bridge can be viewed as a fine partition of the sample space.
Researchers, here modeled by a representative agent,25 independently and randomly choose a strategy at time t based on the number of possible links in the network corresponding to each strategy at that time. This number is then weighted according to a bias parameter that coarsely summarizes the factors influencing this decision. Let Formula be the number of potential jumps, Formula the number of potential new consolidations, Formula the number of potential new bridges, Formula the number of repeat consolidations, and Formula the number of repeat bridges. Formula is thus the number of links that could be repeated and Formula is the number of potential new links. Repeat variables track the total number of repeat links.26 This accounting scheme is consistent with our probabilistic framework: the likelihood that a researcher encounters the opportunity for a repeated link is proportional to its number of repetitions. The probability of each strategy is as follows:
Formula
where Formula is the bias for new relationships, Formula the bias for repeats, Formula for new consolidation, and Formula for repeat consolidation. We fix the bias for jumps at 1 and calculate these other parameters relative to it.27
Conceptually, we imagine that the agent repeats this procedure until it has made the same number of choices as we observe in a given year. Using the aggregate history of strategic choices discussed earlier, we infer bias parameters that maximize the likelihood our agent will generate the observed history. The likelihood of all publication data observed between years  Formula and Formula under this model is as follows:
Formula
The likelihood function depends on the bias parameters through the strategy probabilities (see previous equation). Parameter values are obtained by maximum likelihood estimation. To estimate the parameters for a given year, we use the observed number of links of each type (e.g., ηJ(t) = the number of jumps in year t) from the six previous years as the data in the likelihood function; see Part D of the online supplement for details.28 Estimated bias parameters provide an average description of the preferences held by the scientific community for each type of strategic opportunity, relative to jumping.29 We assign 95 percent Bayesian credible intervals to the parameter point estimates by Monte Carlo sampling. We performed 200,000 iterations for each parameter estimate and constructed intervals in Figure 3B as conservatively as possible (see Part D of the online supplement).
Figure 3A (dashed line) shows that this behavioral model predicts observed behavior reasonably well, with a high correlation between known and predicted values (Pearson’s R = .983). The thick vertical line in Figures 3A and 3B indicates the point (1987) at which parameter estimates are no longer strongly affected by the introduction of annotations in 1980. Significant trends in parameters (Figure 3B) suggest that scientists filter out more new opportunities and become more locally focused as knowledge grows. The left axis of Figure 3B indicates a sharply increasing preference for repeating known links over exploring new ones. The right axis of Figure 3B shows that the preference for new consolidation over bridging has also grown, and may be leveling off, indicating a local focus in the exploration of new relationships. In other words, biomedical chemistry remains in a stable, normal science regime precisely because opportunities for novelty are persistently and increasingly ignored.30 The biomedical habitus, crudely approximated by these parameters, sustains tradition at the expense of innovation.
In our Bourdieusian account of scientific choice, the relevant dispositions must be shaped by more than training or observed strategy prevalence. They must reflect and reinforce distributions of risk and reward. In the next section, we relate strategies to the risks and rewards revealed by the first and second moments of the associated citation distribution. The mean number of citations defines the expected reward for a strategy if published. Standard deviation in citations traces the uncertainty in this reward, conditional on publication. We perform this analysis by applying regression models to pooled and disaggregated, article-level data.
Step 5: Measuring the Relationship between Strategy, Risk, and Reward
We now connect the disposition to pursue tradition (repeat links) over innovation (new and jump links) to the reward mechanisms that drive scientists in their pursuit of recognition. We conjecture that innovation strategies, which are rare and risky, should be more highly rewarded, on average, but face greater uncertainty in reward. In this section, we focus on citations as a form of reward and recognition.
Publication-level strategies
Careful analysis of the relationship between strategy, risk, and reward demands a taxonomy that classifies each publication uniquely. Unique classification assigns a given paper’s citations to only one strategy. Our earlier taxonomy works at the level of individual links. We thus construct a taxonomy at the publication level, based on the link-level strategies deployed. A jump publication has at least one jump link, the least frequent type. A new consolidation publication has at least one new consolidation link, the next least frequent, but no jump links. A new bridge publication has at least one new bridge, but no jumps or new consolidations, and so on through repeat consolidations and repeat bridges. Each publication is thus defined as the outcome of its most distinguishing (and surprising) strategy. Call this first taxonomy “fine-grained.” As in the generative model, we also create a “coarse-grained” taxonomy, separating articles into jump, new, and repeat publications. A jump publication is defined as above; a new publication has at least one new link but no jumps; and a repeat publication has no jumps or new links.31
Surprisal
In information theory, self-information or surprisal measures the information associated with observing outcome i of a discrete random variable (Cover and Thomas 1991). Surprisal is defined as Formula , such that highly improbable outcomes are surprising (high surprisal) and more commonplace outcomes are unsurprising (low surprisal). In our case, the outcomes are observations of a given research strategy. Observations of rare strategies are more surprising and therefore more novel. Strategy surprisal can be defined for the publication-level taxonomy using the relative frequency of the distinctive or eponymous strategy in the prior year as an estimate for its probability in the current year—Formula . For example, the surprisal of a new bridge publication in year t would be Formula .
Citation counts
Citations are assigned to abstracts by linking MEDLINE abstracts to the ThomsonReuters Web of Science citation database. Each abstract is assigned the total citations it received in the three years following initial publication (the median half-life for scientific citations); this effectively implements a medium-term time horizon on scientists’ assessment of reward.32 If an abstract is not in the Web of Science, it is omitted from this analysis. Approximately two-thirds of the MEDLINE abstracts link to a Web of Science record with citation information. We restrict analysis to 1983 to 2002 due to decreased citation coverage post 2005.33
Aggregate analysis: strategy-year models
In these models, we pool all abstracts corresponding to each publication-level strategy in a given year and compute the mean citations and the standard deviation in citations for that pool. We then perform robust regressions (HC3 heteroscedasticity correction) in Stata. For the data partitioned into a fine taxonomy of five strategies (jump, new consolidation, new bridge, repeat consolidation, repeat bridge), we predict the mean and standard deviation of citations using two different models: strategy surprisal and year in one model, and strategy type and year in another.34 For the coarse taxonomy with three strategies (jump, new, repeat) we predict mean citations and standard deviation in citations with strategy type and year.
Aggregate results
Results from these models confirm our conjecture that strategy surprisal positively varies with mean citations, conditional on that strategy being published. Rare innovation strategies have high surprisal. They likely have a harder time being published but garner more attention when they are. Common tradition strategies have low surprisal. Robust regression shows that surprisal alone explains 49 percent of the variation in mean citations; a model including year explains 79 percent. This pattern is also observed when surprisal is replaced with strategy type, treated as an indicator variable. In the five-strategy (fine-grained) model, strategy type alone explains 50 percent of the variation, and the regression coefficients become larger as the strategy becomes more innovative, exactly as predicted. When year is added, we explain 81 percent. Results are very similar for the three-strategy (coarse-grained) model. Strategy type and year together explain 74 percent of the variation.
We also confirm our conjecture that surprisal is positively correlated with the uncertainty of reward, which we operationalized as the standard deviation in citations. The same results obtain when strategy type is used, with the rare, risky strategies again having larger regression coefficients (see Table 2).35 Figure 4A provides a simple visualization of the relationship between tradition, innovation, and mean citations.
View this table:
In this window In a new window
Download to PowerPoint Slide
Table 2.
Models Regressing Citations on Strategy Surprisal or Type
Figure 4.
View larger version:
In this page In a new window
Download to PowerPoint Slide
Figure 4.
Strategies and Citation Impact
Note: (A) Rare innovation strategies are correlated with higher mean citations (49 percent of variation explained). The surprisal of a strategy in year t (horizontal axis) plotted against mean citations received by papers published in year t distinguished by that strategy. Much of the remaining variation is explained by adding year of observation to the model, as citations tend to increase with time (79 percent of variation explained by the combined model; the surprisal coefficient remains significant). (B) The mean citations for a paper depend quadratically on the fraction of links in the paper that correspond to a given strategy. Here we show the results of a negative binomial regression model; the peak occurs at around 40 percent for jump, new consolidation, and new bridge. Note that the response to strategy fraction is strongest for rare innovation strategies.
Article-level analysis
Because each article can be associated with its distinguishing strategy, we can also test the association between strategies and citations on disaggregated article-level data, accounting directly for overdispersion in citations (article level of analysis in Table 2). Citation values are discrete and typically have a broad distribution, with some articles receiving very high citation counts. Indeed, many more highly cited articles occur than would be the case for Poisson-distributed data. This overdispersed behavior defies assumptions of the standard linear regression model, which is why we used a pooling strategy for the OLS analysis. For some model specifications, we can estimate the relationship between citations and research strategies using a negative binomial model, a generalization of the Poisson model that accounts for overdispersion in the data.36 Like Poisson models (Hausman, Hall, and Griliches 1984), negative binomial models assume that the logarithm of the expected value of the dependent variable can be modeled by a linear combination of known predictors. In this sense, it is similar to estimating a simple linear regression with the logarithm of citations as the dependent variable.
To test the effect on citations of strategy type, we assume the following:
Formula
where Formula is the number of citations received by article a in the year a was published and the subsequent three years. We consider two classes of model. For the five-strategy (fine-grained) taxonomy, we construct models using either surprisal or strategy type as a predictor, along with year since 1983. In the first case, the model is
Formula
where strategy surprisal is assigned as above. In the second case, the model is
Formula
where Formula , Formula , and such are indicator variables; Formula is a continuous predictor; and Formula , the error, is assumed to be a gamma distributed random variable. This formulation makes repeat bridge a reference category. For the three-strategy (coarse-grained) taxonomy, we use strategy type and year as predictors:
Formula
where Formula and Formula are indicator variables and Formula and Formula are treated as before. In this model, repeat is used as the reference category.
Article-level results
Our results for this analysis are summarized in Table 2. All coefficients are highly significant. Once again, these models reveal higher average returns to rare, risky, innovation strategies, as predicted by our hypothesis connecting rarity, risk, and reward. In the three-strategy model, for example, a paper deploying a new strategy has 30 percent more citations, on average, than a paper studying only repeat links. A paper deploying a jump strategy has 51 percent more citations, on average, than a more conservative repeat paper.37
Optimal strategy analysis
We also use negative binomial regressions to test a related hypothesis, connecting expected citations to the fraction of links in a given article that correspond to a particular link-level strategy. The interplay of strategy, risk, and reward suggests that articles should be penalized for myopically focusing on one strategy and excluding all others. For example, it is difficult to locate a paper with no repeat links in the existing knowledge network. Such a paper is a radical break with tradition and is likely to be misunderstood or ignored. Likewise, a paper with no new or jump links is at lower risk of being misunderstood, but also at lower risk of being a subversive breakthrough with corresponding high citations. This analysis of the optimal mix of strategies within an article connects directly to recent findings in Uzzi and colleagues (2013).
We use negative binomial regressions to test the connection between expected citations and the fraction of links in a given paper that correspond to a particular link-level strategy. We assume that citations are distributed according to a negative binomial distribution and fit the following model:
Formula
where Formula refers to the proportion of chemical relationships in article a that represent jumps; Formula is the same quantity squared; and Formula , the error, is again assumed to be a gamma distributed random variable. We estimated this model for every other type of relationship (new consolidations, new bridges, repeat consolidations, and repeat bridges) in Stata.
Optimal strategy results
Negative binomial regressions of expected article citations on strategy fraction and fraction-squared bear out our intuition that there should be a robust unimodular relationship between strategy proportion and expected citations (see Part F and Table S4 in the online supplement); Figure 4B depicts that relationship. We find that research attention in the form of citations responds most strongly to variation in strategy proportion for innovation strategies, with pure innovation (all links are jump, new consolidation, or new bridge) highly penalized but modest fractions (around 40 percent) highly rewarded. The citation-optimizing configurations can be explained in the typical case of five chemicals per publication. By adding a single new chemical to four previously connected chemicals from the same subfield, a paper can approach the optimal level: 40 percent jump links and 60 percent repeat consolidation links. Similarly, by newly linking a single known chemical in one knowledge cluster to four connected chemicals in another, a paper can achieve the near optimum: 40 percent new bridge links and 60 percent repeat consolidation links.
At first blush, these proportions appear to disagree with Uzzi and colleagues’ (2013) recent finding that peak impact is associated with articles in the 85th to 95th percentile of median conventionality in their references, implying an overwhelming number of repeat reference combinations. The difference between 60 percent conventional chemical combinations and 90 percent conventional journal combinations is easy to resolve, however, if authors cite familiar literature concerning repeat chemical associations more often than the unfamiliar literature used to justify novel associations.38
We have demonstrated that innovation is more richly rewarded with citations than is tradition. Citations represent one of the fundamental currencies of scientific recognition, so we might reasonably ask whether observed levels of innovation could be motivated purely by citation accumulation, or if additional motivations are needed.39 We take this up in the last empirical section.
Step 6: Analyzing Possible Motivations
Maximizing citations
We verified our conjecture that innovation strategies should be more highly rewarded, on average, than tradition strategies. We also found that they face greater variability in reward following publication (although not a greater risk of being ignored; see note 37). We now consider whether these risk-reward relationships are sufficient to explain the observed distribution of strategies, with innovation (jump, new) rare and tradition (repeat) common. The simplest strategic model of scientific motivation assumes that scientists are trying to maximize citations on a paper-by-paper basis to accumulate scientific capital (Bourdieu 1975). This corresponds to the picture of professional pressure described earlier. To maintain their current position in the scientific field, scientists must reliably publish articles and garner citations for those articles.
This analysis requires that we estimate the chance of utter failure, in which nothing is found or the resulting paper fails to pass peer review. Do innovation strategies attract enough reward to balance this risk? In other words, is a scientist who chooses to innovate pursuing a reasonable strategy, if her goal is to maximize expected citations for that project? We cannot directly observe the probability that a particular strategy will succeed or fail from our data: our sample is drawn only from projects that did produce a publication. We can, however, provide bounds on the failure probability, under the assumption that scientists select strategies only to maximize citations (Bourdieu 1975).40
To analyze whether citation maximization is a credible motivation for the observed distribution of scientists’ research choices, we again study paper-level strategies, now taking into account the a priori probability that a particular strategy yields a publication. The expected citation count for a particular strategy E(citations | S) is the product of the probability of success given that strategy, Pr(publication | S), with the mean citations for published articles employing that strategy—the expected reward conditional on publication, R(citations | publication, S). Note that Pr(publication | S) incorporates both actual failure, in which a project goes nowhere, and publication failure, where the resulting article is censored by peer review.41 Our use of mean citations (Wuchty et al. 2007) reflects the simplest possible utility function for scientists with no risk-aversion or risk-seeking.
For a risk-neutral, citation-maximizing scientist to be indifferent between strategies—for the choice of new or jump instead of repeat to be rational—then E(citations | repeat) = E(citations | new) = E(citations | jump). This equality allows us to place bounds on the probability of success Pr(publication | S) for each strategy. We compute mean citations from the data, averaging over the period 1983 to 2002:42 8.38 for repeat, 11.00 for new, and 12.90 for jump. For the equality to hold, Pr(publication | new) = .76 × Pr(publication | repeat) and Pr(publication | jump) = .65 × Pr(publication | repeat). This means that if scientists were risk-neutral and sought to maximize citations in each paper, a pathbreaking new or jump project is only 24 or 35 percent less likely to succeed than a conservative repeat project. We argue that this is extremely unlikely, and innovation projects are much more likely to fail.
This result suggests that the probability of reaching publication for innovation strategies is sufficiently small that repeat is likely to be the dominant strategy for a scientist seeking to maximize expected citations on each project. Citation-maximization thus supplies plausible motivation for one half of the essential tension, that is, the substantial fraction of scientists who choose tradition over innovation. Systems of professional evaluation like hiring and tenure, which often rest on reliable productivity and citations, strongly push scientists to pursue conservative repeat strategies. But we are left with a puzzle. While scientists eschew most opportunities for high-risk, high-impact work, they still engage more risk than would be rational if they only sought to maximize citations—if they were only concerned with job security and a stable career. This leads us to evaluate another potential motivation: rewards from exceptional scientific achievement, which allow scientists to move up in the field.
Exceptional achievement and prizewinners
Beyond job security, scientists are also motivated by the desire for significant impact and recognition. They wish to leave their mark on history (Merton 1973) and move up in the field (Bourdieu 1975). This level of achievement is captured by the most highly cited papers (Cokol, Rodriguez-Esteban, and Rzhetsky 2007; Wuchty et al. 2007) and even more so by awards and prizes. Such lofty recognition is thought to require riskier, original contributions (Kuhn [1959] 1977; Merton 1949). Hence, we predict that top-cited articles and prizewinners will deploy rare, risky innovation strategies more frequently than will the typical article or scientist.
To analyze the distribution of strategies among award-winning scientists, we compiled a list of 137 prizes and awards in biomedicine and chemistry, drawing on the category pages for biology awards, medicine awards, and chemistry awards on Wikipedia.43 We confirmed the resulting list with several biology, medical, and chemistry researchers.
All prestigious and many less prestigious prizes are listed, providing a broad sample of achievement—from field-specific (e.g., the Anselme Payen award, related to cellulose chemistry) to world-recognized (e.g., the Nobel Prize in Physiology or Medicine). We eliminated all prizes awarded for non-research reasons (e.g., teaching or history) as well as those awarded to students. We then searched the lists of prizewinners against PubMed and hand-selected three articles by each prizewinner, where possible. We expanded the initial set of articles by linking the name of the prizewinner in the MEDLINE entry for each of the seed articles with clusters of disambiguated author names assigned by the Author-ity tool (Smalheiser and Torvik 2009). We then retrieved and associated with the prizewinner all publications authored by Author-ity–linked name variants written up to 30 years before the date of the award.44
To examine truly outstanding achievement, we compiled a list of “elite, general” prizes (see Figure 5B). We included the two Nobel Prizes; prizes explicitly mentioned as being precursors to a Nobel; top general awards given by professional societies in the United States and the United Kingdom (the American Chemical Society, the National Academy of Science, and the Royal Society of Chemistry); and the Wolf Prizes, which have similar stature and prestige. The resulting list of 12 prizes is as follows: Nobel Prize in Physiology or Medicine, Nobel Prize in Chemistry, Louisa Gross Horwitz Prize, Lasker-DeBakey Clinical Medical Research Award, Albert Lasker Award for Basic Medical Research, Gairdner Foundation International Award, NAS Award in Chemical Sciences, Priestley Medal, Corday-Morgan Medal, Grand Prix Charles Leopold Mayer, Wolf Prize in Medicine, and Wolf Prize in Chemistry.
Figure 5.
View larger version:
In this page In a new window
Download to PowerPoint Slide
Figure 5.
Strategies Shift for High Impact Scientists
Note: (A) Pooling all papers published from 1983 to 2002, we find a distribution of strategies similar to that observed in any year (Figure 3A). We judge pools of high impact articles and authors against this baseline. (B) Highly cited articles or those published by prizewinners in the 30 years before receipt of a prize show an enhancement of jumps and new consolidations. The vertical axis measures the observed strategy frequency in each pool as a percentage of the baseline value. 95 percent confidence intervals are indicated by the boxes outside each data point. (C) and (D) As in (B) but for biological and medical prizes, and chemical prizes, respectively. The heavy line shows the aggregate behavior of all prizes in the category; confidence intervals are smaller than the symbols. We also show the most prestigious, general prizes in these fields; confidence intervals are not shown.
Figure 5 verifies with an aggregate analysis that top-cited articles deploy significantly more innovation strategies than all articles as a fraction of links contributed, with the strongest enrichment in jumping and new consolidation. The strategy distribution of typical articles is shown in Figure 5A. The relative enrichment in the top 10, 5, and 1 percent most highly cited articles is shown in Figure 5B, with multinomial confidence intervals at the 95 percent level shown in boxes.
Articles written by authors who won one of 137 different prizes in biomedicine and chemistry show a similar pattern of enrichment (see Figure 5B). This population includes 7,594 awardees and 241,176 articles. Articles written by winners of the most elite awards, including Nobel prizes, not only introduce new chemicals more frequently than those written by typical scientists, but they also more frequently introduce new relationships within knowledge clusters. A novel, integrating link within a chemical cluster attracts the attention of the existing research community whose articles inscribe the connections that define the cluster. Identifying new connections within dense, established clusters of chemicals may also be more difficult, on average, as these connections are more likely to have been tried unsuccessfully in the past by members of the community. In this way, elite award winners may define or transform our understanding of these clusters. The same pattern obtains when we analyze awards by field, grouping them into biomedicine (Figure 5C) and chemistry (Figure 5D).45 Note that these populations also produce (many) tradition links. Highly cited papers and prizewinners simply display a larger proportion of innovation strategies in their output than does the typical scientist.
These results provide a plausible motivational mechanism for the other half of the essential tension, linking risky innovation to extraordinary scientific achievement. As Merton (1968) argues, highly successful scientists are important models of emulation, and insofar as they use risky innovation strategies more frequently, this may inspire other scientists to engage in the occasional risky gamble. This mechanism may be quite general; a similar process has recently been described in filmmaking, where the pursuit of an award also carries considerable risk (Rossman and Schilke 2014).
Previous Section
Next Section
Discussion

Strategic Origins of the Essential Tension
Taken together, our results provide strong quantitative evidence that scientists’ choice of research problem is indeed shaped by their strategic negotiation of an essential tension between productive tradition and risky innovation (Kuhn [1959] 1977). Kuhn’s basic picture, when enriched with Bourdieu’s conception of research choice as strategic action and his notion of scientific habitus, provides a compelling framework in which to understand our findings. Using a network representation of chemical knowledge, we demonstrated that biomedical chemistry is in a normal science regime, with conservative strategies (tradition) common and riskier strategies (innovation) rare. This conservatism is further supported by our finding that knowledge has crystallized into stable knowledge clusters. The distribution of research claims is also remarkably stable. This would be surprising if scientists attended only to research opportunities, but becomes entirely expected if their choices are shaped by a complex of socially inflected dispositions and incentives. Using a simple behavioral model, we relate these stable choices to exploding opportunities for biomedical novelty, and we measure the growing biases that focus scientists on the known. We then provide a quantitative analysis of some of the incentives that undergird those biases. In this, we confirm that innovation strategies are not only rare but also more highly rewarded and, in all likelihood, more risky. Finally, we sketch out and quantitatively confirm two motivational explanations for tradition and innovation. We find that a disposition toward tradition is plausibly adapted to maximizing productivity and reliably accumulating scientific capital, while a disposition toward occasional innovation is motivated by a gamble for posterity and a desire to achieve higher position in the field. We believe our results, taken as stylized facts about stability, dispositions, risk-reward, and motivational mechanisms, are robust to the necessary modeling assumptions we made and the limitations of the data outlined in the next section.
Limitations of the Current Study and Robustness of Results to Selection
Broad limitations
Our analysis builds on much recent research in the social science of innovation but draws together many effects in a single case; it thus serves as the first large-scale confirmation of a key concept in the qualitative study of science and innovation. Despite our novel methods and our analysis of a new, large dataset, this study has several limitations. Protocols for chemical annotation at the National Library of Medicine are not uniform over time. Our method necessarily misses relationships whose chemicals are not in the NLM annotation. By considering all co-mentioned chemicals, we also allow some “false relationships,” failing to distinguish between substantial and incidental associations. Moreover, our taxonomy of research strategies does not reflect the full variety of factors scientists consider. More precise extraction of chemical relationships (Evans and Foster 2011; Evans and Rzhetsky 2011), a broader full-text corpus including research proposals, and richer models can transcend these limits.
Selection effect
Strategies that failed to yield publishable findings are excluded from our analysis because we focus on publications. Low-risk incremental strategies may be more prevalent in our corpus not just because scientists choose them more frequently, but also because they fail less frequently, leading to publication more often. Risky strategies, as suggested by the name, fail more frequently, and thus remain unpublished, a phenomenon often known as the “file drawer” problem (Rosenthal 1979). This suggests that taking the distribution of strategies in the literature as representative of the underlying distribution of strategies may misestimate the actual prevalence of a given strategy in scientists’ aggregate research effort.
In fact, our results are largely unaffected by this filtering process. Our finding of stability stands, unless there is temporal variation in the probability that various strategies succeed or fail. Our proposed connection between risk and reward also stands: if research failures were routinely published, it would enhance the correlation between strategy surprisal and variance in citations by disproportionately adding unpublished and uncited risky attempts to our sample. The claim that high-achieving scientists visibly produce more high-risk research is also unaffected by this selection. We note that the simplest explanation for a higher prevalence of risky strategies among high-achieving scientists is that they engage in risky research efforts more often, consistent with our theory and analysis. Another plausible explanation, which we pose as a research question, is that these scientists succeed more frequently in their risky efforts, either by skill in problem selection, pure luck, or greater success in the exercise of symbolic power (i.e., getting innovations accepted).46 These alternatives do not affect the conclusion that high achievement is visibly associated with riskier strategies and consequently likely to motivate risk-taking in other scientists. Finally, policy prescriptions that promote more risk-taking will lead to a higher prevalence of risky strategies. If incentives for risk-taking are extreme, diminishing returns may obtain as scientists are pushed into outlandish projects, but it is implausible that we are near this point in the current policy regime. A myopic focus on novelty contributes to increased publication of novel yet spurious results (Ioannidis 2005a, 2005b), while a focus on tradition increases the likelihood of needless repetition and spurious incremental findings. An increase in the supply of risky projects will lead to their higher prevalence in publications.
The only claim directly affected by the selection effect is the relative rank of strategy prevalence in science. It is impossible to validate this using our data. Recall that repeated chemical relationships are half an order of magnitude more frequent in published findings than new relationships, and new relationships half an order of magnitude more frequent than jumps. The size of these differences suggests that the underlying effort distribution in science is probably reflected in the rank order of published strategy prevalence. Its plausibility is further bolstered by a reasonable risk assessment of the various strategies and widely documented, subjectively valid concerns about pressures for productivity, which prioritize conservative, reliable repeat strategies.
Previous Section
Next Section
Conclusions

Understanding the research process remains a central challenge for science studies, and improved understanding will be key to improved science policy (Evans and Foster 2011). Science is a complex system (Foote 2007), and new methods like ours can identify some of the processes that govern its evolution. Our research suggests one reason why unexpected findings that change the landscape of science are infrequent. Pursuing innovation is a gamble, without enough payoff, on average, to justify the risk. Nevertheless, science benefits when individuals overcome the dispositions that orient them toward established islands of knowledge (Cokol et al. 2005) in the expanding ocean of possible topics. Early breakthroughs in literature-based discovery illustrated the power of linking islands of knowledge together (Swanson 1990). Our results explain why such discovery methods remain fruitful.
To be sure, not all scientists should pursue risky strategies. Normal science that characterizes a known relationship more deeply has its own value, as recognized by Kuhn ([1959] 1977). Nevertheless, stimulating innovation is an important goal of science policy, and we suggest two policy levers to promote risk-taking. The first involves decoupling job security from productivity, which can encourage originality, as was the case at Bell Labs (Gertner 2012). So can funding scientists rather than projects, as at the Howard Hughes Medical Institute and a new family of grants at the National Institutes of Health.47 These policies follow from the insight that career pressure represents a powerful incentive for conservative behavior.48 The other lever sits outside the tension between productivity and posterity: agencies can lower the barriers to risky projects by funding them more aggressively, like the Gates Foundation. These interventions may be able to counter the stable conservatism we uncover here.
Our paper also has implications for the sociology of science and for sociological methodology more broadly. First, our findings suggest new research questions in the sociology of science. For example, how do strategies change over a scientific career? How does local context shape strategic choice? Are high-achieving scientists initiators of more risky projects, more far-sighted, more capable of exercising symbolic power, or simply luckier? And how are the dispositions of risk-taking scientists (Bateman and Hess 2015) constituted? Our study also suggests that new methods for representing scientific knowledge and modeling scientific incentives and behavior can bring big data to bear in evaluating the scope of rich qualitative insights from science studies, the sociology of scientific knowledge, and the anthropology and history of science (Evans and Foster 2011). Our method should extend to other fields, as long as we can identify plausible building blocks of content. For example, consider PACS codes in physics, MSC codes in mathematics, USPTO classification codes in patents, and classification codes or author-assigned keywords in sociology. We believe that new methods should be developed for mining building blocks with finer granularity—comparable to chemicals—and for defining strategies beyond the combinatorial. The broad contours of our findings should carry over to other relatively stable disciplines characterized by substantial consensus on core elements and on which combinations of these elements are valid and interesting. It would be especially intriguing to extend our analysis along the lines suggested by Panofsky (2011), combining the two forms of scientific capital examined here (citations and awards) with more and less external and exchangeable capitals (e.g., reputation in other fields, funding, and patents).
As we noted earlier, the essential tension has been studied many times under many names. Our empirical findings and theoretical framework make important advances beyond simply bringing together multiple phenomena identified in isolated studies from the sociology, economics, and management of innovation. First, contrary to Kuhn and in keeping with Bourdieu, we find a coexistence of conservative tradition and radical innovation strategies within a field—and within a paper. Second, we find increased emphasis on tradition relative to novel opportunities as the space of possibilities expands. Third, we find that novel connections within fields are more highly rewarded—innovation within tradition—which is unanticipated under many theories of interdisciplinarity (e.g., those based on structural holes). Fourth, we provide and substantiate a fundamentally strategic account of the essential tension, sharply at odds with Kuhn’s internal cognitive account and building usefully on Bourdieu’s. Under our account, a disposition toward tradition is reflected and reproduced by the relationship between expected reward and expected risk, which is further modulated by the screening processes of scientific peer review. We find it surprising that innovation is relatively unrewarded in the day-to-day currency of scientific credit (citations), given how rare and risky innovation is and how highly novelty is prized. This may, in part, reflect the insensitivity of our approach to innovation beyond the combination of chemicals (e.g., the linkage of a chemical with a novel method or disease). It may also reflect the absolute difficulty of moving new relationships, once accepted as provisionally legitimate, into the category of legitimate and interesting. Cultivating such interest may require substantial mobilization (Frickel and Gross 2005). Finally, the apparent division of motivational labor between citations (as an anticipated reward for traditional work) and awards (as a hard-to-anticipate reward for innovation) is novel and has not been documented before.
Methodologically, our analysis makes three contributions. First, it provides a template for applying the machinery of network analysis to scientific content, and suggests that such methods can be fruitfully applied to other forms of content. Second, it demonstrates that, if one is willing to tolerate simplification, rich sociological constructs like the habitus can be represented in formal models and measured (as stylized facts) on large scales, extending the quantitative aspects of Bourdieu’s program beyond correspondence analysis (Bourdieu 1984) and creating surprising connections with analytic sociology (Hedström 2005). Finally, our paper argues for the utility of simple probabilistic models of behavior coupled with maximum likelihood inference. Such generative models are a happy compromise between the behavioral plausibility of agent-based models and the closeness to data of classical regression analysis, and there is much room for extending our simple generative model to incorporate rich representations of individual dispositions and field positions. To put it reflexively: our paper is grounded in several traditions from the sociology of science, network analysis, and statistical modeling. In making novel connections within and between them, it contributes substantive or methodological innovations to each.
Previous Section
Next Section
Acknowledgments

We are grateful for helpful comments from Carl Bergstrom, David Blei, Charles Camic, Erica Cartmill, and Steve Epstein. We also received valuable feedback from audiences at Duke University, Princeton University, the University of California-Los Angeles, the University of Chicago, the University of Michigan, Harvard Business School, and the American Sociological Association. We thank Martin Rosvall and Daniel Edler for generous assistance with use of their MapEquation software package; Jeff Alstott for help with his Python package powerlaw; research assistants Mahmoud Bahrani, Simo Huang, David Kates, and Val Michelman for help compiling data on prizewinners in biomedicine and chemistry; the National Library of Medicine and Jane Rosov for assistance with MEDLINE chemical annotations; and ThomsonReuters for making their citation information available. This work was supported by NSF grant SBE 0915730 and a grant (ID: 39147) to the Metaknowledge Network by the John Templeton Foundation.
